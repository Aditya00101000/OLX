# olx_car_cover_scraper.py

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv

def scrape_olx_car_covers():
    # Set up headless Chrome
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    try:
        url = "https://www.olx.in/items/q-car-cover"
        driver.get(url)
        time.sleep(5)  # Wait for JS content

        # Scroll to bottom to load listings
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)

        # Find listings
        items = driver.find_elements(By.CSS_SELECTOR, "li.EIR5N")
        results = []

        for item in items:
            try:
                title = item.find_element(By.CSS_SELECTOR, "span._2tW1I").text
                price = item.find_element(By.CSS_SELECTOR, "span._89yzn").text
                location = item.find_element(By.CSS_SELECTOR, "span._2tW1I._2_dZ3").text
                link = item.find_element(By.TAG_NAME, "a").get_attribute("href")
                results.append([title, price, location, link])
            except:
                continue  # Skip incomplete listings

        # Save to CSV
        with open("olx_car_covers.csv", "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Title", "Price", "Location", "Link"])
            writer.writerows(results)

        print("âœ… Saved results to 'olx_car_covers.csv'")

    finally:
        driver.quit()

if __name__ == "__main__":
    scrape_olx_car_covers()
